filter {

    if "JIRA" in [tags] {

        # Following Jira logs are not (yet) parsed or processed, so not available in ElasticSearch / Kibana:
        # opt:
        # - localhost.*.log                     empty files
        # - manager.*.log                       empty files
        # - host-manager.*.log                  empty files
        # var:
        # - atlassian-jira-incoming-mail.log*   included in atlassian.out
        # - atlassian-jira.log*                 included in atlassian.out
        # - atlassian-servicedesk.log           module not used anymore

        # set logtrail field for all Jira logfiles
        mutate {
            add_field => { "logtrail" => "Atlassian - Jira" }
            add_tag => [ "CP70_MUT01" ]
        }

        if [log][file][path] =~ /access.log/ {
            grok {
                match => { "message" => "^%{IP:clientip}(,%{IP:proxyip})? %{NOTSPACE:requestid} %{HTTPDUSER:auth} \[%{HTTPDATE:timestamp}\] \"%{GREEDYDATA:rawrequest}\" (%{INT:response}|-) (%{INT:bytes_read}|-) (%{INT:bytes_written}|-) (%{QS:referrer}|-) \"?%{QS:agent}\"? (%{QS:sessionid}|-)" }
                add_tag => [ "CP70_GRO01" ]
            }
        }

        if [log][file][path] =~ /atlassian-jira-security.log/ {
            grok {
                match => { "message" => "^%{TIMESTAMP_ISO8601:timestamp} %{NOTSPACE:thread} %{HTTPDUSER:auth}? %{HTTPDUSER:requestid}? %{NOTSPACE:sessionid}? (%{IPORHOST:clientip}(,%{IPORHOST:proxyip})?(,%{IPORHOST:serverip})?)? (%{RIT_SERVICE:request})? %{JAVALOGMESSAGE:log_message}" }
                add_tag => [ "CP70_GRO02" ]
            }
        }

        if [log][file][path] =~ /atlassian-jira-slow-queries.log/ {
            grok {
                match => { "message" => "^%{TIMESTAMP_ISO8601:timestamp} %{PROG:thread} %{LOGLEVEL:level} %{USER:auth}? %{HTTPDUSER:requestid}? %{NOTSPACE:sessionid}? (%{RIT_SERVICE:request})? %{SYSLOG5424SD:class} %{JAVALOGMESSAGE:log_message}" }
                add_tag => [ "CP70_GRO03" ]
            }
            grok {
                match => { "log_message" => "^JQL query '%{DATA:slow_query.jql}' produced lucene query '%{DATA:slow_query.lucene}' and took '%{POSINT:slow_query.duration_in_ms}' ms to run." }
                match => { "log_message" => "^LuceneQueryExecutionEvent{query=%{GREEDYDATA:slow_query.lucene}}" }
                add_tag => [ "CP70_GRO04" ]
            }
        }

        if [log][file][path] =~ /catalina.out/ or [log][file][path] =~ /catalina(.*).log/ {
            # Following message overflood logging (approx 65% of lines in catalina.out) and are not required
            # (https://jira.atlassian.com/browse/JRASERVER-34570), so exclude them:
            # - datahub@maastrichtuniversity.nl datahub@maastrichtuniversity.nl[10100]: Cannot handle message as the recipient(s) (.....) do not match the catch email datahub@maastrichtuniversity.nl
            # - castor-datahub@mumc.nl castor-datahub@mumc.nl[10100]: Cannot handle message as the recipient(s) (....) do not match the catch email castor-datahub@mumc.nl
            # - Datahub@mumc.nl Datahub@mumc.nl[10100]: Cannot handle message as the recipient(s) (.....) do not match the catch email datahub@mumc.nl
            if [message] =~ /Cannot handle message as the recipient/ {drop { }}

            # Content from following files is included in catalina.out. Therefore these logfiles won't be parsed explicitly:
            # - atlassian-jira.log
            # - atlassian-jira-incoming-mail.log

            # catalina logs and out files contain logs from multiple sources with different formatting, hence the multiple grok patterns
            grok {
                break_on_match => true
                match => { "message" => "^%{TOMCAT8_DATESTAMP:timestamp} %{LOGLEVEL:level} %{SYSLOG5424SD:thread} %{JAVACLASS:class} %{JAVALOGMESSAGE:log_message}" }
                # log-pattern of atlassian-jira-incoming-mail.log
                match => { "message" => "^%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{SYSLOG5424SD:mailserver} %{RIT_PROG:thread} %{USER:auth}? %{HTTPDUSER:requestid}? %{NOTSPACE:sessionid}? (%{IPORHOST:clientip},(%{IPORHOST:proxyip},)?%{IPORHOST:serverip})? (%{RIT_SERVICE:reqeust_url})? %{JAVALOGMESSAGE:log_message}" }
                # log-pattern of atlassian-jira.log
                match => { "message" => "^%{TIMESTAMP_ISO8601:timestamp} %{DATA:thread}(:(thread-)?%{INT:tid})? %{LOGLEVEL:level} %{USER:auth}? %{HTTPDUSER:requestid}? %{NOTSPACE:sessionid}? (%{IPORHOST:clientip},(%{IPORHOST:proxyip},)?%{IPORHOST:serverip})? (%{NOTSPACE:request})? %{SYSLOG5424SD:class} %{JAVALOGMESSAGE:log_message}" }
                # exception lines in catalina.out
                match => { "message" => "^Exception in thread \"%{JAVACLASS:class}:thread-%{INT:tid}\" %{JAVACLASS:log_msg1}: %{JAVACLASS:log_msg2}.*\n%{GREEDYDATA:stacktrace}"}
                add_tag => [ "CP70_GRO05" ]
            }
            if [log_msg1] {
                mutate {
                    add_field => { "level" => "ERROR" }
                    replace => { "log_message" => "%{log_msg1}: %{log_msg2}" }
                    remove_field => [ "log_msg1", "log_msg2" ]
                    add_tag => [ "CP70_MUT02" ]
                }
            }
        }

    }


    if "CONFLUENCE" in [tags] {

        # Following Confluence logs are not (yet) parsed or processed, so not available in ElasticSearch / Kibana:
        # opt:
        # - catalina.*.log                      included in catalina.out
        # - gc*.log.*                           java garbage collection logs are different (regarding type and format), don't seem to be usefull atm
        # - localhost.*.log                     empty files
        # - manager.*.log                       empty files
        # - host-manager.*.log                  empty files
        # var:
        # - atlassian-synchrony.log*            seems not that important and unclear (yet) how to parse json logfile

        # set logtrail field
        mutate {
            add_field => { "logtrail" => "Atlassian - Confluence" }
            add_tag => [ "CP70_MUT03" ]
        }

        if [log][file][path] =~ /atlassian-confluence.log/ {
            grok {
                match => { "message" => "^%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{SYSLOG5424SD:thread} %{SYSLOG5424SD:class} %{NOTSPACE:http_method} %{JAVALOGMESSAGE:log_message}$" }
                add_tag => [ "CP70_GRO06" ]
            }
        }

        if [log][file][path] =~ /atlassian-synchrony-proxy.log/ { # from "opt" location!!
            grok {
                match => { "message" => "^%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{JAVALOGMESSAGE:log_message}$" }
                add_tag => [ "CP70_GRO07" ]
            }
        }

        if [log][file][path] =~ /catalina.out/ {
            grok {
                break_on_match => true
                match => { "message" => "^%{BIND9_TIMESTAMP:timestamp} %{LOGLEVEL:level} %{SYSLOG5424SD:thread} %{NOTSPACE:class} %{JAVALOGMESSAGE:log_message}" }
                match => { "message" => "^%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{SYSLOG5424SD:thread} \[%{JAVACLASS:class}\] %{JAVALOGMESSAGE:log_message}" }
                match => { "message" => "^%{TIMESTAMP_ISO8601:timestamp}\n%{JAVALOGMESSAGE:log_message}" }
                match => { "message" => "^\[%{PROG:thread}] %{LOGLEVEL:level} %{JAVACLASS:class} - %{GREEDYDATA:log_message}" }
                add_tag => [ "CP70_GRO08" ]
            }
        }

    }


    if "BITBUCKET" in [tags] {

        # Following Bitbucket logs are not (yet) parsed or processed, so not available in ElasticSearch / Kibana:
        # opt:
        # - catalina.*.log                      included in catalina.out
        # - manager.*.log                       empty files
        # - host-manager.*.log                  empty files
        # var:
        # -

        # set logtrail field
        mutate {
            add_field => { "logtrail" => "Atlassian - Bitbucket" }
            add_tag => [ "CP70_MUT04" ]
        }

        if [log][file][path] =~ /catalina.out/ {
            grok {
                match => { "message" => "^%{TOMCAT8_DATESTAMP:timestamp} %{LOGLEVEL:level} %{SYSLOG5424SD:thread} %{NOTSPACE:class} %{JAVALOGMESSAGE:log_message}" }
                add_tag => [ "CP70_GRO09" ]
            }
        }

        if [log][file][path] =~ /localhost(.*).log/ {
            grok {
                break_on_match => true
                match => { "message" => "%{TOMCAT8_DATESTAMP:timestamp} %{LOGLEVEL:level} %{SYSLOG5424SD:thread} %{JAVACLASS:class} %{JAVACLASS:subclass} %{LOGLEVEL}: %{JAVALOGMESSAGE:log_message}" }
                match => { "message" => "%{TOMCAT8_DATESTAMP:timestamp} %{LOGLEVEL:level} %{SYSLOG5424SD:thread} %{NOTSPACE:class} %{JAVALOGMESSAGE:log_message}" }
                match => { "message" => "^%{TOMCAT8_DATESTAMP:timestamp} %{LOGLEVEL:level} %{SYSLOG5424SD:thread} %{JAVALOGMESSAGE:log_message}" }
                add_tag => [ "CP70_GRO10" ]
            }
        }

        if [log][file][path] =~ /atlassian-bitbucket.log/ or [log][file][path] =~ /atlassian-bitbucket-\d\d\d\d-\d\d-\d\d\.log/ {
            grok {
                break_on_match => true
                match => { "message" => "^%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} +%{SYSLOG5424SD:thread} (%{USER:auth} )?%{NOTSPACE:requestid} (%{NOTSPACE:sessionid} )?%{IP:clientip},%{IP:proxyip} %{QUOTEDSTRING:rawrequest} %{JAVACLASS:class} %{JAVALOGMESSAGE:log_message}$" }
                match => { "message" => "^%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} +%{SYSLOG5424SD:thread}  %{JAVACLASS:class} %{JAVALOGMESSAGE:log_message}$" }
                add_tag => [ "CP70_GRO11" ]
            }
        }

        if [log][file][path] =~ /atlassian-bitbucket-access/ {
            grok {
                match => { "message" => "^%{IP:clientip}(,%{IP:proxyip})?(,%{IP:serverip})? \| %{NOTSPACE:protocol} \| %{NOTSPACE:requestid} \| %{USER:auth} \| %{TIMESTAMP_ISO8601:timestamp} \| \"?%{DATA:rawrequest}\"? \| (%{QS:referrer}|-) (%{QS:agent} )?\| (%{INT:response}|-) \| (%{INT:bytes_read}|-) \| (%{INT:bytes_written}|-) \| (%{DATA:labels_atl}|-) \| (%{INT:response_time}|-) \| (%{NOTSPACE:sessionid}|-) \|" }
                add_tag => [ "CP70_GRO12" ]
            }
        }

        if [log][file][path] =~ /atlassian-bitbucket-mail/ {
            grok {
                match => { "message" => "^%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} +%{SYSLOG5424SD:thread}  %{NOTSPACE:class} %{JAVALOGMESSAGE:log_message}$" }
                add_tag => [ "CP70_GRO13" ]
            }
        }

        if [log][file][path] =~ /atlassian-bitbucket-audit/ {
            grok {
                match => { "message" => "^(%{IPORHOST:clientip}(,%{IPORHOST:proxyip})?|-) \| %{NOTSPACE:event_name} \| %{USER:auth} \| %{NUMBER:timestamp} \| %{NOTSPACE:auth} \| %{DATA:event_details} \| %{NOTSPACE:requestid} \| (%{NOTSPACE:sessionid}|-)$" }
                add_tag => [ "CP70_GRO14" ]
            }
        }

        if [log][file][path] =~ /bitbucket_search.log/ {
            grok {
                match => { "message" => "^\[%{TIMESTAMP_ISO8601:timestamp}\]\[%{LOGLEVEL:level}( +)?\]\[%{NOTSPACE:class}( +)?] %{JAVALOGMESSAGE:log_message}$" }
                add_tag => [ "CP70_GRO15" ]
            }
#            if [log_message] =~ /disk watermark(.*)exceeded on(.*)free/ {
#                grok {
#                    match => { "log_message" => "^\[bitbucket_bundled\] (high|low) disk watermark \[%{NUMBER:disk_used_perc}\%\] exceeded on %{SYSLOG5424SD:disk_id}\[bitbucket_bundled\]%{SYSLOG5424SD:disk_path} free: %{NOTSPACE:diskspace_free}\[%{NUMBER:diskspace_free_perc}(.*)" }
#                }
#            }
        }

    }

    if "APACHE" in [tags] {
        # first parse the access and error logs
        if [log][file][path] =~ /access/ {
            grok {
                match => { "message" => "%{COMBINEDAPACHELOG}" }
                add_tag => [ "CP70_GRO16" ]
            }
            mutate {
                add_field => { "level" => "INFO" }
                add_tag => [ "CP70_MUT05" ]
            }
        }
        if [log][file][path] =~ /error/ {
            # HTTPD24_ERRORLOG reuses field message. To preserve original content of message, store it in field raw
            mutate {
                add_field => { "raw" => "%{message}" }
                add_tag => [ "CP70_MUT05" ]
            }
            grok {
                match => { "message" => "%{HTTPD24_ERRORLOG}" }
                match => { "message" => "^%{WORD:errorcode}: %{JAVALOGMESSAGE:log_message}" }
                add_tag => [ "CP70_GRO17" ]
            }
            mutate {
                uppercase => ["level"]
                rename => { "client" => "clientip" }
                rename => { "message" => "log_message" }
                # restore field message with original value
                rename => { "raw" => "message" }
                add_tag => [ "CP70_MUT07" ]
            }
        }

        # filebeat.prospector for apache logs doesn't set tags for jira, confluence or bitbuckt, so set them here
        if [log][file][path] =~ /jira-access.log/ {
            mutate {
                add_tag => [ "JIRA" ]
                add_field => { "logtrail" => "Atlassian - Jira" }
                add_tag => [ "CP70_MUT08" ]
            }
        }
        if [log][file][path] =~ /confluence-access.log/ {
            mutate {
                add_tag => [ "CONFLUENCE" ]
                add_field => { "logtrail" => "Atlassian - Confluence" }
                add_tag => [ "CP70_MUT09" ]
            }
        }
        if [log][file][path] =~ /bitbucket-access.log/ {
            mutate {
                add_tag => [ "BITBUCKET" ]
                add_field => { "logtrail" => "Atlassian - Bitbucket" }
                add_tag => [ "CP70_MUT10" ]
            }
        }
        if ![logtrail] {
            mutate {
                add_field => { "logtrail" => "Atlassian - Apache" }
                add_tag => [ "CP70_MUT11" ]
            }
        }

    }


    if "ATLASSIAN" in [tags] {
        # parse rawrequest into http_method, request and http version
        if [rawrequest] {
            grok {
                match => { "rawrequest" => "^(%{NOTSPACE:http_method} %{NOTSPACE:request} HTTP/%{NOTSPACE:httpversion})?" }
                add_tag => [ "CP70_GRO18" ]
            }
        }
        # set event timestamp to timestamp (as provided by the logfile)
        date {
            match => [ "timestamp",
                       "ISO8601",                               # catalina.out, catalina.*.log, security.log, confluence.log
                       "dd-MMM-YYYY HH:mm:ss.SSS",              # catalina.out (diff format)
                       "dd-MMM-YYYY HH:mm:ss,SSS",              # catalina.out (diff format)
                       "YYYY-MM-dd HH:mm:ss",                   # catalina out (diff format)
                       "dd/MMM/YYYY:HH:mm:ss Z",                # access_log timestamp format
                       "UNIX_MS",                               # epoch timestamp (used in audit log)
                       "EEE MMM dd HH:mm:ss.SSSSSS YYYY" ]      # apache error logs
            timezone => "Europe/Amsterdam"
            locale => "en"
            remove_field => [ "timestamp" ]                     # cleanup, data is now available in @timestamp
            add_tag => [ "CP70_DAT01" ]
        }
    }
}